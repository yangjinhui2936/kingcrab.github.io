# Lecture 4: Transformers

## Video

<iframe width="560" height="315" src="https://www.youtube.com/embed/lOYT3-UbUvw" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## Slides

<iframe src="//www.slideshare.net/slideshow/embed_code/key/9f22eS7VTxHplM" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe>

[Download slides as PDF](https://drive.google.com/file/d/16wOruUY4x3tdeTncwi3AdoM75ZE57Gr4/view?usp=sharing)

## Notes

*Lecture by [Sergey Karayev](https://sergeykarayev.com).*

In this video, you will learn about the origin of transfer learning in computer vision, its application in NLP in the form of embedding, NLP's ImageNet moment, and the Transformers model families.

- 00:00 - Introduction
- 00:42 - Transfer Learning in Computer Vision
- 04:00 - Embeddings and Language Models
- 10:09 - NLP's ImageNet moment: ELMO and ULMFit on datasets like SQuAD, SNLI, and GLUE
- 16:49 - Rise of Transformers
- 18:20 - Attention in Detail: (Masked) Self-Attention, Positional Encoding, and Layer Normalization
- 27:33 - Transformers Variants: BERT, GPT/GPT-2/GPT-3, DistillBERT, T5, etc.
- 36:20 - GPT3 Demos
- 42:53 - Future Directions
